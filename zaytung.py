from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd

# TarayÄ±cÄ± ayarlarÄ±nÄ± yap
options = webdriver.ChromeOptions()
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36")

# TarayÄ±cÄ±yÄ± baÅŸlat
driver = webdriver.Chrome(options=options)

# **KaÃ§ sayfa olduÄŸunu bulalÄ±m**
driver.get("https://www.zaytung.com/digerleri.asp")
wait = WebDriverWait(driver, 10)

try:
    # Sayfa numaralarÄ±nÄ± bulalÄ±m (En son sayfa numarasÄ±nÄ± alacaÄŸÄ±z)
    page_numbers = wait.until(EC.presence_of_all_elements_located((By.XPATH, "//a[contains(@href, 'digerleri.asp?pg=')]")))
    
    # TÃ¼m sayfa numaralarÄ±nÄ± al
    pages = [int(p.text) for p in page_numbers if p.text.isdigit()]
    max_page = max(pages) if pages else 1  # En bÃ¼yÃ¼k sayfa numarasÄ±nÄ± bul
    print(f"ğŸ“Œ Toplam {max_page} sayfa bulundu.")
    
except:
    max_page = 1  # EÄŸer sayfa sayÄ±sÄ±nÄ± bulamazsak en az 1 olsun


# **KaÃ§ sayfa Ã§ekileceÄŸini ayarla (Ä°lk 20 sayfa)**
num_pages = min(100, max_page)  # En fazla 20 sayfa Ã§ek, ancak toplam sayfadan azsa onu kullan

news_data = []

# **Åimdi belirlenen sayÄ±da sayfadan haberleri Ã§ekelim**
for page in range(1, num_pages + 1):  
    url = f"https://www.zaytung.com/digerleri.asp?pg={page}"
    driver.get(url)
    print(f"ğŸ“Œ {page}. sayfadaki haberleri Ã§ekiyoruz...")

    try:
        # SayfanÄ±n tamamen yÃ¼klenmesini bekleyelim
        wait = WebDriverWait(driver, 15)

        # **TÃ¼m haber baÅŸlÄ±klarÄ±nÄ± al**
        news_items = wait.until(EC.presence_of_all_elements_located((By.XPATH, "//td/h3/a")))

        for item in news_items:
            try:
                title = item.text.strip()
                link = item.get_attribute("href")  # Link tamamlama

                # Haber verisini sayfa numarasÄ±yla birlikte kaydet (summary kaldÄ±rÄ±ldÄ±)
                news_data.append([title, link, page])

            except Exception as e:
                print("Hata:", e)

    except Exception as e:
        print(f"{page}. sayfa yÃ¼klenirken hata oluÅŸtu: {e}")

# **Tekrar eden haberleri temizleyelim**
df = pd.DataFrame(news_data, columns=["Title", "Link", "Page"])

print("Tekrarlar temizlenmeden Ã¶nceki satÄ±r sayÄ±sÄ±:", len(df))

df = df.drop_duplicates(subset=["Title"], keep="first")

df.reset_index(drop=True, inplace=True)

print("Tekrarlar temizlendikten sonraki satÄ±r sayÄ±sÄ±:", len(df))

# DataFrame'i CSV dosyasÄ±na aktar
csv_filename = 'zaytung_haberler.csv'
df.to_csv(csv_filename, index=False, encoding='utf-8-sig') # utf-8-sig encoding TÃ¼rkÃ§e karakterler iÃ§in Ã¶nemli
print(f"âœ… Haberler baÅŸarÄ±yla '{csv_filename}' dosyasÄ±na kaydedildi.")

# TarayÄ±cÄ±yÄ± kapat
driver.quit()